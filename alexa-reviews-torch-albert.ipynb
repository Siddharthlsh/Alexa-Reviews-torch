{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de6af0a4",
   "metadata": {
    "papermill": {
     "duration": 0.015748,
     "end_time": "2023-11-30T10:39:17.990140",
     "exception": false,
     "start_time": "2023-11-30T10:39:17.974392",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Alexa Reviews torch ALBERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efeaf6d2",
   "metadata": {
    "papermill": {
     "duration": 0.014287,
     "end_time": "2023-11-30T10:39:18.019683",
     "exception": false,
     "start_time": "2023-11-30T10:39:18.005396",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "ALBERT is a model developed by Google AI, and is a simplified version of BERT that maintains performance while reducing the number of parameters. In the sentence judgment task, it shows performance equal to or better than BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a975fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:18.051694Z",
     "iopub.status.busy": "2023-11-30T10:39:18.050493Z",
     "iopub.status.idle": "2023-11-30T10:39:33.949711Z",
     "shell.execute_reply": "2023-11-30T10:39:33.948176Z"
    },
    "papermill": {
     "duration": 15.917958,
     "end_time": "2023-11-30T10:39:33.952781",
     "exception": false,
     "start_time": "2023-11-30T10:39:18.034823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting chardet\r\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.4/199.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: chardet\r\n",
      "Successfully installed chardet-5.2.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install chardet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34fe9d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-28T07:17:40.740526Z",
     "iopub.status.busy": "2023-06-28T07:17:40.740151Z",
     "iopub.status.idle": "2023-06-28T07:17:40.744782Z",
     "shell.execute_reply": "2023-06-28T07:17:40.743875Z"
    },
    "papermill": {
     "duration": 0.014239,
     "end_time": "2023-11-30T10:39:33.982201",
     "exception": false,
     "start_time": "2023-11-30T10:39:33.967962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "    debug = False\n",
    "    debug2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca20976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:34.015197Z",
     "iopub.status.busy": "2023-11-30T10:39:34.014726Z",
     "iopub.status.idle": "2023-11-30T10:39:41.585683Z",
     "shell.execute_reply": "2023-11-30T10:39:41.584401Z"
    },
    "papermill": {
     "duration": 7.590864,
     "end_time": "2023-11-30T10:39:41.588500",
     "exception": false,
     "start_time": "2023-11-30T10:39:33.997636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import transformers\n",
    "import random\n",
    "import chardet\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "002251aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:41.621218Z",
     "iopub.status.busy": "2023-11-30T10:39:41.620513Z",
     "iopub.status.idle": "2023-11-30T10:39:41.635338Z",
     "shell.execute_reply": "2023-11-30T10:39:41.634055Z"
    },
    "papermill": {
     "duration": 0.034747,
     "end_time": "2023-11-30T10:39:41.638220",
     "exception": false,
     "start_time": "2023-11-30T10:39:41.603473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_seed(SEED):\n",
    "    \n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "SEED = 508\n",
    "random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c8b391b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:41.669914Z",
     "iopub.status.busy": "2023-11-30T10:39:41.669503Z",
     "iopub.status.idle": "2023-11-30T10:39:41.695965Z",
     "shell.execute_reply": "2023-11-30T10:39:41.694794Z"
    },
    "papermill": {
     "duration": 0.04557,
     "end_time": "2023-11-30T10:39:41.698682",
     "exception": false,
     "start_time": "2023-11-30T10:39:41.653112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8-SIG\n"
     ]
    }
   ],
   "source": [
    "with open('/kaggle/input/amazon-alexa-reviews/amazon_alexa.tsv', 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "print(result['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc95b838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:41.732666Z",
     "iopub.status.busy": "2023-11-30T10:39:41.732079Z",
     "iopub.status.idle": "2023-11-30T10:39:41.816116Z",
     "shell.execute_reply": "2023-11-30T10:39:41.814938Z"
    },
    "papermill": {
     "duration": 0.104846,
     "end_time": "2023-11-30T10:39:41.819138",
     "exception": false,
     "start_time": "2023-11-30T10:39:41.714292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loved it!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Music</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>Perfect for kids, adults and everyone in betwe...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3146</th>\n",
       "      <td>Listening to music, searching locations, check...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>I do love these things, i have them running my...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>Only complaint I have is that the sound qualit...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3149</th>\n",
       "      <td>Good</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3150 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       verified_reviews  rating\n",
       "0                                         Love my Echo!       5\n",
       "1                                             Loved it!       5\n",
       "2     Sometimes while playing a game, you can answer...       4\n",
       "3     I have had a lot of fun with this thing. My 4 ...       5\n",
       "4                                                 Music       5\n",
       "...                                                 ...     ...\n",
       "3145  Perfect for kids, adults and everyone in betwe...       5\n",
       "3146  Listening to music, searching locations, check...       5\n",
       "3147  I do love these things, i have them running my...       5\n",
       "3148  Only complaint I have is that the sound qualit...       5\n",
       "3149                                               Good       4\n",
       "\n",
       "[3150 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('/kaggle/input/amazon-alexa-reviews/amazon_alexa.tsv', sep='\\t',\n",
    "                 encoding=result['encoding'])\n",
    "data=data[['verified_reviews','rating']]\n",
    "data=data.dropna()\n",
    "display(data)\n",
    "data.columns=['text','targets']\n",
    "classes=sorted(data['targets'].unique().tolist())\n",
    "print(classes)\n",
    "class_names=list('12345')\n",
    "N=list(range(len(class_names)))\n",
    "normal_mapping=dict(zip(class_names,N)) \n",
    "reverse_mapping=dict(zip(N,class_names))       \n",
    "#data['targets']=data['targets'].map(normal_mapping)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b367bbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:41.852431Z",
     "iopub.status.busy": "2023-11-30T10:39:41.851990Z",
     "iopub.status.idle": "2023-11-30T10:39:41.860084Z",
     "shell.execute_reply": "2023-11-30T10:39:41.858826Z"
    },
    "papermill": {
     "duration": 0.02747,
     "end_time": "2023-11-30T10:39:41.862603",
     "exception": false,
     "start_time": "2023-11-30T10:39:41.835133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3150\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "data=data.sample(frac=1).reset_index(drop=True)[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cb9884e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:41.896150Z",
     "iopub.status.busy": "2023-11-30T10:39:41.895440Z",
     "iopub.status.idle": "2023-11-30T10:39:41.903282Z",
     "shell.execute_reply": "2023-11-30T10:39:41.902117Z"
    },
    "papermill": {
     "duration": 0.027702,
     "end_time": "2023-11-30T10:39:41.905780",
     "exception": false,
     "start_time": "2023-11-30T10:39:41.878078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc89f83d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:41.939999Z",
     "iopub.status.busy": "2023-11-30T10:39:41.939584Z",
     "iopub.status.idle": "2023-11-30T10:39:43.780962Z",
     "shell.execute_reply": "2023-11-30T10:39:43.779732Z"
    },
    "papermill": {
     "duration": 1.862416,
     "end_time": "2023-11-30T10:39:43.783985",
     "exception": false,
     "start_time": "2023-11-30T10:39:41.921569",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4e0a498b3b547d3b156b0ff9f118bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6d17b5d0f0444497868c8e8fd35549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.AlbertTokenizer.from_pretrained(\"albert-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60457129",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:43.818543Z",
     "iopub.status.busy": "2023-11-30T10:39:43.818136Z",
     "iopub.status.idle": "2023-11-30T10:39:43.823487Z",
     "shell.execute_reply": "2023-11-30T10:39:43.822378Z"
    },
    "papermill": {
     "duration": 0.025493,
     "end_time": "2023-11-30T10:39:43.825954",
     "exception": false,
     "start_time": "2023-11-30T10:39:43.800461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")\n",
    "#tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e56059be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:43.860249Z",
     "iopub.status.busy": "2023-11-30T10:39:43.859798Z",
     "iopub.status.idle": "2023-11-30T10:39:52.699375Z",
     "shell.execute_reply": "2023-11-30T10:39:52.698105Z"
    },
    "papermill": {
     "duration": 8.859945,
     "end_time": "2023-11-30T10:39:52.701980",
     "exception": false,
     "start_time": "2023-11-30T10:39:43.842035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i love it. easy set up as well[SEP]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_s = train['text'].iloc[0]\n",
    "result1 = tokenizer.encode_plus(test_s)\n",
    "tokenizer.decode(result1[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9afde9ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:52.736119Z",
     "iopub.status.busy": "2023-11-30T10:39:52.735666Z",
     "iopub.status.idle": "2023-11-30T10:39:52.743510Z",
     "shell.execute_reply": "2023-11-30T10:39:52.742279Z"
    },
    "papermill": {
     "duration": 0.028192,
     "end_time": "2023-11-30T10:39:52.746158",
     "exception": false,
     "start_time": "2023-11-30T10:39:52.717966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_s.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b9ac946",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:52.780013Z",
     "iopub.status.busy": "2023-11-30T10:39:52.779597Z",
     "iopub.status.idle": "2023-11-30T10:39:52.785627Z",
     "shell.execute_reply": "2023-11-30T10:39:52.784479Z"
    },
    "papermill": {
     "duration": 0.025681,
     "end_time": "2023-11-30T10:39:52.787895",
     "exception": false,
     "start_time": "2023-11-30T10:39:52.762214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result2 = tokenizer.encode_plus(\n",
    "    test_s,\n",
    "    add_special_tokens = True, \n",
    "    max_length = 8, \n",
    "    pad_to_max_length = True, \n",
    "    truncation = True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bb8c1e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:52.822278Z",
     "iopub.status.busy": "2023-11-30T10:39:52.821890Z",
     "iopub.status.idle": "2023-11-30T10:39:52.828764Z",
     "shell.execute_reply": "2023-11-30T10:39:52.827673Z"
    },
    "papermill": {
     "duration": 0.02726,
     "end_time": "2023-11-30T10:39:52.831099",
     "exception": false,
     "start_time": "2023-11-30T10:39:52.803839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] i love it. easy[SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(result2[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc7b8b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:52.865965Z",
     "iopub.status.busy": "2023-11-30T10:39:52.865485Z",
     "iopub.status.idle": "2023-11-30T10:39:52.878615Z",
     "shell.execute_reply": "2023-11-30T10:39:52.877569Z"
    },
    "papermill": {
     "duration": 0.034001,
     "end_time": "2023-11-30T10:39:52.881571",
     "exception": false,
     "start_time": "2023-11-30T10:39:52.847570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sens = 8\n",
    "train = train.sort_values('targets').reset_index(drop=True)\n",
    "train[\"kfold\"] = train.index % 5\n",
    "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\n",
    "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n",
    "p_test=test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f974c87",
   "metadata": {
    "papermill": {
     "duration": 0.017039,
     "end_time": "2023-11-30T10:39:52.916000",
     "exception": false,
     "start_time": "2023-11-30T10:39:52.898961",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "'token_type_ids' no need in RoBERTa/DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1952cbf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:52.950947Z",
     "iopub.status.busy": "2023-11-30T10:39:52.950536Z",
     "iopub.status.idle": "2023-11-30T10:39:52.960161Z",
     "shell.execute_reply": "2023-11-30T10:39:52.959056Z"
    },
    "papermill": {
     "duration": 0.029919,
     "end_time": "2023-11-30T10:39:52.962700",
     "exception": false,
     "start_time": "2023-11-30T10:39:52.932781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self,sentences,targets):        \n",
    "        self.sentences = sentences\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):        \n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self,idx):        \n",
    "        sentence = self.sentences[idx]    \n",
    "        bert_sens = tokenizer.encode_plus(\n",
    "                                sentence,\n",
    "                                add_special_tokens = True, \n",
    "                                max_length = max_sens, \n",
    "                                pad_to_max_length = True, \n",
    "                                return_attention_mask = True)\n",
    "\n",
    "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
    "\n",
    "        target = torch.tensor(self.targets[idx],dtype=torch.float)\n",
    "        \n",
    "        return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'targets': target\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a414f10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:52.997541Z",
     "iopub.status.busy": "2023-11-30T10:39:52.997132Z",
     "iopub.status.idle": "2023-11-30T10:39:53.006247Z",
     "shell.execute_reply": "2023-11-30T10:39:53.005079Z"
    },
    "papermill": {
     "duration": 0.029474,
     "end_time": "2023-11-30T10:39:53.008693",
     "exception": false,
     "start_time": "2023-11-30T10:39:52.979219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = BERTDataSet(p_train[\"text\"],p_train['targets'])\n",
    "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['targets'])\n",
    "test_dataset = BERTDataSet(p_test[\"text\"],p_test['targets'])\n",
    "\n",
    "train_batch = 16\n",
    "valid_batch = 32\n",
    "test_batch = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=8,pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=8,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=8,pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8380306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:53.043507Z",
     "iopub.status.busy": "2023-11-30T10:39:53.042801Z",
     "iopub.status.idle": "2023-11-30T10:39:55.219305Z",
     "shell.execute_reply": "2023-11-30T10:39:55.218363Z"
    },
    "papermill": {
     "duration": 2.196776,
     "end_time": "2023-11-30T10:39:55.221817",
     "exception": false,
     "start_time": "2023-11-30T10:39:53.025041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff270bf366b483d88030a3df392ae46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0034d5bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:55.257512Z",
     "iopub.status.busy": "2023-11-30T10:39:55.257098Z",
     "iopub.status.idle": "2023-11-30T10:39:55.262603Z",
     "shell.execute_reply": "2023-11-30T10:39:55.261367Z"
    },
    "papermill": {
     "duration": 0.026166,
     "end_time": "2023-11-30T10:39:55.264974",
     "exception": false,
     "start_time": "2023-11-30T10:39:55.238808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=1)\n",
    "#model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32082b17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:55.303520Z",
     "iopub.status.busy": "2023-11-30T10:39:55.302239Z",
     "iopub.status.idle": "2023-11-30T10:39:55.315595Z",
     "shell.execute_reply": "2023-11-30T10:39:55.314448Z"
    },
    "papermill": {
     "duration": 0.035069,
     "end_time": "2023-11-30T10:39:55.318045",
     "exception": false,
     "start_time": "2023-11-30T10:39:55.282976",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlbertForSequenceClassification(\n",
       "  (albert): AlbertModel(\n",
       "    (embeddings): AlbertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 128)\n",
       "      (token_type_embeddings): Embedding(2, 128)\n",
       "      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0, inplace=False)\n",
       "    )\n",
       "    (encoder): AlbertTransformer(\n",
       "      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n",
       "      (albert_layer_groups): ModuleList(\n",
       "        (0): AlbertLayerGroup(\n",
       "          (albert_layers): ModuleList(\n",
       "            (0): AlbertLayer(\n",
       "              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (attention): AlbertAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (attention_dropout): Dropout(p=0, inplace=False)\n",
       "                (output_dropout): Dropout(p=0, inplace=False)\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              )\n",
       "              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (pooler_activation): Tanh()\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b2d835b",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:55.355753Z",
     "iopub.status.busy": "2023-11-30T10:39:55.354601Z",
     "iopub.status.idle": "2023-11-30T10:39:56.171530Z",
     "shell.execute_reply": "2023-11-30T10:39:56.170201Z"
    },
    "papermill": {
     "duration": 0.83916,
     "end_time": "2023-11-30T10:39:56.174388",
     "exception": false,
     "start_time": "2023-11-30T10:39:55.335228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "for a in train_dataloader:\n",
    "    ids = a[\"ids\"].to(device)\n",
    "    mask = a[\"mask\"].to(device)\n",
    "    output = model(ids,mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38cb617d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:56.211799Z",
     "iopub.status.busy": "2023-11-30T10:39:56.211370Z",
     "iopub.status.idle": "2023-11-30T10:39:56.220819Z",
     "shell.execute_reply": "2023-11-30T10:39:56.220018Z"
    },
    "papermill": {
     "duration": 0.030785,
     "end_time": "2023-11-30T10:39:56.223068",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.192283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = output[\"logits\"].squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edef54b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:56.260457Z",
     "iopub.status.busy": "2023-11-30T10:39:56.259528Z",
     "iopub.status.idle": "2023-11-30T10:39:56.277226Z",
     "shell.execute_reply": "2023-11-30T10:39:56.275991Z"
    },
    "papermill": {
     "duration": 0.039424,
     "end_time": "2023-11-30T10:39:56.280153",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.240729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "LR=2e-5\n",
    "optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65e12948",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:56.318185Z",
     "iopub.status.busy": "2023-11-30T10:39:56.317105Z",
     "iopub.status.idle": "2023-11-30T10:39:56.326691Z",
     "shell.execute_reply": "2023-11-30T10:39:56.325750Z"
    },
    "papermill": {
     "duration": 0.031139,
     "end_time": "2023-11-30T10:39:56.328957",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.297818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 20\n",
    "#if debug:\n",
    "#    epochs = 1\n",
    "train_steps = int(len(p_train)/train_batch*epochs)\n",
    "print(train_steps)\n",
    "num_steps = int(train_steps*0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9847bbbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:56.367814Z",
     "iopub.status.busy": "2023-11-30T10:39:56.367137Z",
     "iopub.status.idle": "2023-11-30T10:39:56.371906Z",
     "shell.execute_reply": "2023-11-30T10:39:56.370957Z"
    },
    "papermill": {
     "duration": 0.026575,
     "end_time": "2023-11-30T10:39:56.374189",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.347614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(output,target):\n",
    "    return torch.sqrt(nn.MSELoss()(output,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7ddf6d",
   "metadata": {
    "papermill": {
     "duration": 0.017758,
     "end_time": "2023-11-30T10:39:56.410443",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.392685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# def training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af265416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:56.449208Z",
     "iopub.status.busy": "2023-11-30T10:39:56.448494Z",
     "iopub.status.idle": "2023-11-30T10:39:56.460727Z",
     "shell.execute_reply": "2023-11-30T10:39:56.459457Z"
    },
    "papermill": {
     "duration": 0.035029,
     "end_time": "2023-11-30T10:39:56.463476",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.428447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler\n",
    "):\n",
    "    \n",
    "    model.train()\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    allpreds = []\n",
    "    alltargets = []\n",
    "\n",
    "    for a in train_dataloader:\n",
    "\n",
    "        losses = []\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "\n",
    "            ids = a[\"ids\"].to(device,non_blocking=True)\n",
    "            mask = a[\"mask\"].to(device,non_blocking=True)\n",
    "\n",
    "            output = model(ids,mask)\n",
    "            output = output[\"logits\"].squeeze(-1)\n",
    "            target = a[\"targets\"].to(device,non_blocking=True)\n",
    "            loss = loss_fn(output,target)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "            allpreds.append(output.detach().cpu().numpy())\n",
    "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
    "\n",
    "        scaler.scale(loss).backward() \n",
    "        scaler.step(optimizer) \n",
    "        scaler.update() \n",
    "        \n",
    "        del loss \n",
    "\n",
    "        scheduler.step() \n",
    "\n",
    "    allpreds = np.concatenate(allpreds)\n",
    "    alltargets = np.concatenate(alltargets)\n",
    "    losses = np.mean(losses)\n",
    "    train_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
    "\n",
    "    return losses,train_rme_loss\n",
    "#losses,train_rme_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7279685d",
   "metadata": {
    "papermill": {
     "duration": 0.017454,
     "end_time": "2023-11-30T10:39:56.499011",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.481557",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# def validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4d9ee7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:56.538536Z",
     "iopub.status.busy": "2023-11-30T10:39:56.538110Z",
     "iopub.status.idle": "2023-11-30T10:39:56.549203Z",
     "shell.execute_reply": "2023-11-30T10:39:56.548266Z"
    },
    "papermill": {
     "duration": 0.033047,
     "end_time": "2023-11-30T10:39:56.551554",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.518507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validating(valid_dataloader,model):\n",
    "    \n",
    "    model.eval()\n",
    "    allpreds = []\n",
    "    alltargets = []\n",
    "\n",
    "    for a in valid_dataloader:\n",
    "        losses = []\n",
    "        with torch.no_grad():\n",
    "\n",
    "            ids = a[\"ids\"].to(device)\n",
    "            mask = a[\"mask\"].to(device)\n",
    "\n",
    "            output = model(ids,mask)\n",
    "            output = output[\"logits\"].squeeze(-1)\n",
    "            target = a[\"targets\"].to(device)\n",
    "            loss = loss_fn(output,target)\n",
    "            losses.append(loss.item())\n",
    "            allpreds.append(output.detach().cpu().numpy())\n",
    "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
    "            \n",
    "            del loss\n",
    "\n",
    "    allpreds = np.concatenate(allpreds)\n",
    "    alltargets = np.concatenate(alltargets)\n",
    "    losses = np.mean(losses)\n",
    "    valid_rme_loss = np.sqrt(mean_squared_error(alltargets,allpreds))\n",
    "\n",
    "    return allpreds,losses,valid_rme_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ef37be",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-28T07:18:50.544897Z",
     "iopub.status.busy": "2023-06-28T07:18:50.542988Z",
     "iopub.status.idle": "2023-06-28T07:20:42.634766Z",
     "shell.execute_reply": "2023-06-28T07:20:42.633451Z"
    },
    "papermill": {
     "duration": 0.018616,
     "end_time": "2023-11-30T10:39:56.588807",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.570191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "    if debug2 == False:\n",
    "        for a in range(epochs):\n",
    "            for b in train_dataloader:\n",
    "                break\n",
    "\n",
    "        losses,train_rme_loss = training(train_dataloader,model,optimizer,scheduler)\n",
    "\n",
    "        for a in valid_dataloader:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc8e6e5",
   "metadata": {
    "papermill": {
     "duration": 0.018142,
     "end_time": "2023-11-30T10:39:56.625397",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.607255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07eac465",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:39:56.663918Z",
     "iopub.status.busy": "2023-11-30T10:39:56.662657Z",
     "iopub.status.idle": "2023-11-30T10:51:37.602779Z",
     "shell.execute_reply": "2023-11-30T10:51:37.600957Z"
    },
    "papermill": {
     "duration": 700.962727,
     "end_time": "2023-11-30T10:51:37.605951",
     "exception": false,
     "start_time": "2023-11-30T10:39:56.643224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 3.992885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  5%|▌         | 1/20 [00:35<11:17, 35.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.6290249\n",
      "Save first model\n",
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.1764219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0720143\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:11<10:39, 35.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.071108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0042623\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:47<10:07, 35.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.933295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9571709\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:22<09:30, 35.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.8635654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 25%|██▌       | 5/20 [02:57<08:49, 35.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0300968\n",
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.8674262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 30%|███       | 6/20 [03:31<08:11, 35.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9782365\n",
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.7708835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 35%|███▌      | 7/20 [04:06<07:35, 35.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9588062\n",
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.6198959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9244004\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [04:42<07:02, 35.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5484011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 45%|████▌     | 9/20 [05:18<06:30, 35.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0379462\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.4852121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|█████     | 10/20 [05:54<05:55, 35.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9746073\n",
      "---------------10start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.4594932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 55%|█████▌    | 11/20 [06:29<05:19, 35.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9958772\n",
      "---------------11start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.35917282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 60%|██████    | 12/20 [07:04<04:43, 35.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9669309\n",
      "---------------12start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.30081412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 13/20 [07:39<04:07, 35.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9287282\n",
      "---------------13start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.267833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.918246\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [08:14<03:30, 35.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------14start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.24826783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 75%|███████▌  | 15/20 [08:49<02:54, 34.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.93918854\n",
      "---------------15start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.22643845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|████████  | 16/20 [09:23<02:19, 34.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.927468\n",
      "---------------16start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.22432221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 85%|████████▌ | 17/20 [09:58<01:44, 34.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9309742\n",
      "---------------17start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.2066691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|█████████ | 18/20 [10:32<01:09, 34.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.94137156\n",
      "---------------18start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.20288159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 19/20 [11:06<00:34, 34.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.93227464\n",
      "---------------19start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.19959088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 20/20 [11:40<00:00, 35.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.93013895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainlosses = []\n",
    "vallosses = []\n",
    "bestscore = None\n",
    "trainscores = []\n",
    "validscores = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    print(\"---------------\" + str(epoch) + \"start-------------\")\n",
    "    \n",
    "    trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)    \n",
    "    trainlosses.append(trainloss)\n",
    "    trainscores.append(trainscore)\n",
    "    \n",
    "    print(\"trainscore is \" + str(trainscore))\n",
    "    \n",
    "    preds,validloss,valscore=validating(valid_dataloader,model)    \n",
    "    vallosses.append(validloss)\n",
    "    validscores.append(valscore)\n",
    "    \n",
    "    print(\"valscore is \" + str(valscore))\n",
    "    \n",
    "    if bestscore is None:\n",
    "        bestscore = valscore\n",
    "        \n",
    "        print(\"Save first model\")\n",
    "        \n",
    "        state = {\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer_dict': optimizer.state_dict(),\n",
    "                        \"bestscore\":bestscore\n",
    "                    }\n",
    "            \n",
    "        torch.save(state, \"model0.pth\")\n",
    "        \n",
    "    elif bestscore > valscore:\n",
    "        \n",
    "        bestscore = valscore        \n",
    "        print(\"found better point\")        \n",
    "        state = {\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer_dict': optimizer.state_dict(),\n",
    "                        \"bestscore\":bestscore\n",
    "                    }\n",
    "            \n",
    "        torch.save(state, \"model0.pth\")\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "259b7abd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:51:37.705438Z",
     "iopub.status.busy": "2023-11-30T10:51:37.704846Z",
     "iopub.status.idle": "2023-11-30T10:51:38.746308Z",
     "shell.execute_reply": "2023-11-30T10:51:38.745027Z"
    },
    "papermill": {
     "duration": 1.0948,
     "end_time": "2023-11-30T10:51:38.748954",
     "exception": false,
     "start_time": "2023-11-30T10:51:37.654154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(p_valid['targets'],preds, alpha=0.2)\n",
    "plt.title('Validation Prediction Result')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(epochs)\n",
    "plt.title('Validation Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x,trainlosses)\n",
    "plt.plot(x,vallosses)\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(epochs)\n",
    "plt.title('Validation Scores')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.plot(x,trainscores)\n",
    "plt.plot(x,validscores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "88484bf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T10:51:38.851263Z",
     "iopub.status.busy": "2023-11-30T10:51:38.850350Z",
     "iopub.status.idle": "2023-11-30T10:51:38.869783Z",
     "shell.execute_reply": "2023-11-30T10:51:38.868649Z"
    },
    "papermill": {
     "duration": 0.073735,
     "end_time": "2023-11-30T10:51:38.872265",
     "exception": false,
     "start_time": "2023-11-30T10:51:38.798530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.0000    0.0000    0.0000         9\n",
      "           2     0.2500    0.2500    0.2500         4\n",
      "           3     0.1111    0.1111    0.1111         9\n",
      "           4     0.2683    0.4783    0.3438        23\n",
      "           5     0.8962    0.8261    0.8597       115\n",
      "\n",
      "    accuracy                         0.6750       160\n",
      "   macro avg     0.3051    0.3331    0.3129       160\n",
      "weighted avg     0.6952    0.6750    0.6798       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_true = p_valid['targets']\n",
    "val_pred = []\n",
    "for p in preds:\n",
    "    val_pred+=[round(p,0)]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_true,val_pred,target_names=class_names,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f665db",
   "metadata": {
    "papermill": {
     "duration": 0.050663,
     "end_time": "2023-11-30T10:51:38.974792",
     "exception": false,
     "start_time": "2023-11-30T10:51:38.924129",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec34f8cf",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-11-30T10:51:39.078558Z",
     "iopub.status.busy": "2023-11-30T10:51:39.077768Z",
     "iopub.status.idle": "2023-11-30T11:38:44.366126Z",
     "shell.execute_reply": "2023-11-30T11:38:44.364604Z"
    },
    "papermill": {
     "duration": 2825.343663,
     "end_time": "2023-11-30T11:38:44.368942",
     "exception": false,
     "start_time": "2023-11-30T10:51:39.025279",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 3.58817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  5%|▌         | 1/20 [00:35<11:10, 35.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 2.8585837\n",
      "Save first model\n",
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.8664395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1002375\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:11<10:48, 36.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0742264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0616492\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:46<10:04, 35.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.9959029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0119252\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:23<09:32, 35.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.88788766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 25%|██▌       | 5/20 [02:59<09:00, 36.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0416918\n",
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.8278979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0008162\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [03:35<08:25, 36.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.6763121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 35%|███▌      | 7/20 [04:11<07:47, 35.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0770057\n",
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5753733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|████      | 8/20 [04:45<07:05, 35.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0249361\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.48284668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 45%|████▌     | 9/20 [05:20<06:27, 35.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0686979\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.50062346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|█████     | 10/20 [05:55<05:52, 35.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0751168\n",
      "---------------10start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.47964373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 55%|█████▌    | 11/20 [06:31<05:18, 35.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0582769\n",
      "---------------11start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.41582522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 60%|██████    | 12/20 [07:06<04:42, 35.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0415868\n",
      "---------------12start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.38003203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 13/20 [07:42<04:08, 35.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0469688\n",
      "---------------13start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.67531693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|███████   | 14/20 [08:17<03:31, 35.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0926048\n",
      "---------------14start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0165304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 75%|███████▌  | 15/20 [08:54<02:59, 35.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0959806\n",
      "---------------15start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.91560096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|████████  | 16/20 [09:32<02:25, 36.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0457664\n",
      "---------------16start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.64456314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 85%|████████▌ | 17/20 [10:09<01:49, 36.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0744982\n",
      "---------------17start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.6047593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|█████████ | 18/20 [10:45<01:13, 36.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0721495\n",
      "---------------18start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5805105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 19/20 [11:21<00:36, 36.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0676012\n",
      "---------------19start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5690376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 20/20 [11:58<00:00, 35.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0693831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 4.1056194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  5%|▌         | 1/20 [00:36<11:37, 36.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 4.3602967\n",
      "Save first model\n",
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 2.5423818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1179985\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:12<10:47, 35.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.1710076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0899681\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:47<10:09, 35.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.1456834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 20%|██        | 4/20 [02:23<09:29, 35.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0905406\n",
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.1195557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0884212\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [02:58<08:50, 35.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.1084955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 30%|███       | 6/20 [03:32<08:12, 35.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0946256\n",
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.1159347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0693858\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [04:08<07:37, 35.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0727859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|████      | 8/20 [04:43<07:03, 35.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1003169\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.09106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0273226\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [05:18<06:27, 35.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.95495373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.994885\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [05:54<05:55, 35.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------10start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.87793434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9921717\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [06:30<05:21, 35.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------11start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.75170064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9822756\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [07:06<04:45, 35.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------12start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.68967664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 13/20 [07:41<04:09, 35.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9944899\n",
      "---------------13start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.61231285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|███████   | 14/20 [08:17<03:33, 35.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.040382\n",
      "---------------14start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.57514316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 75%|███████▌  | 15/20 [08:53<02:57, 35.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.98799527\n",
      "---------------15start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.516996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|████████  | 16/20 [09:28<02:22, 35.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0665683\n",
      "---------------16start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.4983036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 85%|████████▌ | 17/20 [10:04<01:47, 35.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9878355\n",
      "---------------17start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.47102815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|█████████ | 18/20 [10:39<01:11, 35.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.009036\n",
      "---------------18start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.43918848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 19/20 [11:15<00:35, 35.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9893298\n",
      "---------------19start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.42335176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 20/20 [11:50<00:00, 35.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9932972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 3.7002227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  5%|▌         | 1/20 [00:36<11:30, 36.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.9327985\n",
      "Save first model\n",
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.2671083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2225727\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:12<10:47, 35.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.2465374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1004542\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:47<10:09, 35.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.1149583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0915827\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [02:23<09:34, 35.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0885636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 25%|██▌       | 5/20 [02:58<08:54, 35.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1283195\n",
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.1010695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0894318\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [03:34<08:20, 35.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.1139743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0806657\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [04:10<07:42, 35.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0949007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|████      | 8/20 [04:44<07:04, 35.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.120775\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.115011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0731428\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [05:19<06:27, 35.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0713478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0538118\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [05:55<05:53, 35.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------10start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0695552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.025931\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [06:30<05:17, 35.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------11start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0507944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0217216\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [07:05<04:41, 35.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------12start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0168583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 13/20 [07:40<04:05, 35.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0597389\n",
      "---------------13start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.95607185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.98246175\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [08:15<03:30, 35.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------14start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.89016956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 75%|███████▌  | 15/20 [08:50<02:55, 35.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.99462724\n",
      "---------------15start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.8566814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.972609\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [09:25<02:20, 35.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------16start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.8776204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9686067\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [10:00<01:45, 35.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------17start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.7750348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|█████████ | 18/20 [10:35<01:09, 34.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0100343\n",
      "---------------18start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.76183313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 19/20 [11:09<00:34, 34.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9714775\n",
      "---------------19start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.7154083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 20/20 [11:43<00:00, 35.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.96968615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 3.852259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  5%|▌         | 1/20 [00:35<11:13, 35.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.535779\n",
      "Save first model\n",
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.1426606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1214778\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [01:10<10:28, 34.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0274775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.97167164\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [01:44<09:50, 34.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.9799509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 20%|██        | 4/20 [02:18<09:11, 34.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0183425\n",
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.8138676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 25%|██▌       | 5/20 [02:52<08:36, 34.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9848628\n",
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.7234836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 30%|███       | 6/20 [03:27<08:01, 34.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.98737615\n",
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.571443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 35%|███▌      | 7/20 [04:01<07:27, 34.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0130899\n",
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.51883775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|████      | 8/20 [04:36<06:53, 34.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0000613\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.48317763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 45%|████▌     | 9/20 [05:11<06:20, 34.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.02171\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.42446122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|█████     | 10/20 [05:45<05:45, 34.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0199852\n",
      "---------------10start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.3957333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 55%|█████▌    | 11/20 [06:20<05:11, 34.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0113491\n",
      "---------------11start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.3394282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 60%|██████    | 12/20 [06:55<04:36, 34.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0023782\n",
      "---------------12start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.31975776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 65%|██████▌   | 13/20 [07:29<04:01, 34.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0278454\n",
      "---------------13start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.30030724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|███████   | 14/20 [08:03<03:26, 34.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0176288\n",
      "---------------14start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.29787785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 75%|███████▌  | 15/20 [08:38<02:52, 34.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 0.9923128\n",
      "---------------15start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.29403865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|████████  | 16/20 [09:12<02:17, 34.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0124702\n",
      "---------------16start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.2725691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 85%|████████▌ | 17/20 [09:47<01:43, 34.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0150547\n",
      "---------------17start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.26552132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|█████████ | 18/20 [10:21<01:08, 34.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0210025\n",
      "---------------18start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.26028898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 95%|█████████▌| 19/20 [10:56<00:34, 34.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0186536\n",
      "---------------19start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.25172585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████| 20/20 [11:30<00:00, 34.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0150028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bestscores = []\n",
    "bestscores.append(bestscore)\n",
    "\n",
    "for fold in range(1,5):\n",
    "    \n",
    "    # initializing the data\n",
    "    p_train = train[train[\"kfold\"]!=fold].reset_index(drop=True)\n",
    "    p_valid = train[train[\"kfold\"]==fold].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BERTDataSet(p_train[\"text\"],p_train['targets'])\n",
    "    valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['targets'])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=4,pin_memory=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=4,pin_memory=True)\n",
    "\n",
    "    model = transformers.AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels=1)\n",
    "\n",
    "    model.to(device)\n",
    "    LR=2e-5\n",
    "    optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n",
    "    train_steps = int(len(p_train)/train_batch*epochs)\n",
    "    num_steps = int(train_steps*0.1)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
    "\n",
    "    trainlosses = []\n",
    "    vallosses = []\n",
    "    bestscore = None\n",
    "    trainscores = []\n",
    "    validscores = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        print(\"---------------\" + str(epoch) + \"start-------------\")\n",
    "\n",
    "        trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
    "        trainlosses.append(trainloss)\n",
    "        trainscores.append(trainscore)\n",
    "\n",
    "        print(\"trainscore is \" + str(trainscore))\n",
    "\n",
    "        preds,validloss,valscore=validating(valid_dataloader,model)\n",
    "        vallosses.append(validloss)\n",
    "        validscores.append(valscore)\n",
    "\n",
    "        print(\"valscore is \" + str(valscore))\n",
    "\n",
    "        if bestscore is None:\n",
    "            bestscore = valscore\n",
    "\n",
    "            print(\"Save first model\")\n",
    "\n",
    "            state = {\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'optimizer_dict': optimizer.state_dict(),\n",
    "                            \"bestscore\":bestscore\n",
    "                        }\n",
    "\n",
    "            torch.save(state, \"model\" + str(fold) + \".pth\") \n",
    "\n",
    "        elif bestscore > valscore:\n",
    "            bestscore = valscore\n",
    "            print(\"found better point\")\n",
    "\n",
    "            state = {\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'optimizer_dict': optimizer.state_dict(),\n",
    "                            \"bestscore\":bestscore\n",
    "                        }\n",
    "            torch.save(state, \"model\"+ str(fold) + \".pth\")\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    bestscores.append(bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d8fe3a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T11:38:44.644163Z",
     "iopub.status.busy": "2023-11-30T11:38:44.643404Z",
     "iopub.status.idle": "2023-11-30T11:38:44.651309Z",
     "shell.execute_reply": "2023-11-30T11:38:44.650484Z"
    },
    "papermill": {
     "duration": 0.148235,
     "end_time": "2023-11-30T11:38:44.653503",
     "exception": false,
     "start_time": "2023-11-30T11:38:44.505268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.918246, 1.0008162, 0.9822756, 0.9686067, 0.97167164]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8842bffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T11:38:44.927124Z",
     "iopub.status.busy": "2023-11-30T11:38:44.926635Z",
     "iopub.status.idle": "2023-11-30T11:38:44.933093Z",
     "shell.execute_reply": "2023-11-30T11:38:44.931829Z"
    },
    "papermill": {
     "duration": 0.148066,
     "end_time": "2023-11-30T11:38:44.935698",
     "exception": false,
     "start_time": "2023-11-30T11:38:44.787632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 0.96832323\n"
     ]
    }
   ],
   "source": [
    "np.mean(bestscores)\n",
    "print(\"cv = \" + str(np.mean(bestscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac2eb2f",
   "metadata": {
    "papermill": {
     "duration": 0.13424,
     "end_time": "2023-11-30T11:38:45.205264",
     "exception": false,
     "start_time": "2023-11-30T11:38:45.071024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# def predicting\n",
    "not use saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e259011",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T11:38:45.477453Z",
     "iopub.status.busy": "2023-11-30T11:38:45.477060Z",
     "iopub.status.idle": "2023-11-30T11:38:45.485922Z",
     "shell.execute_reply": "2023-11-30T11:38:45.484637Z"
    },
    "papermill": {
     "duration": 0.149042,
     "end_time": "2023-11-30T11:38:45.488666",
     "exception": false,
     "start_time": "2023-11-30T11:38:45.339624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predicting(test_dataloader,model):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()   \n",
    "    allpreds = []\n",
    "    preds = []\n",
    "    allvalloss=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for a in test_dataloader:\n",
    "\n",
    "            ids = a[\"ids\"].to(device)\n",
    "            mask = a[\"mask\"].to(device)\n",
    "\n",
    "            output = model(ids,mask)\n",
    "            output = output[\"logits\"].squeeze(-1)\n",
    "            preds.append(output.cpu().numpy())\n",
    "\n",
    "        preds = np.concatenate(preds)\n",
    "        allpreds.append(preds)\n",
    "\n",
    "    return allpreds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9cb634",
   "metadata": {
    "papermill": {
     "duration": 0.134563,
     "end_time": "2023-11-30T11:38:45.757184",
     "exception": false,
     "start_time": "2023-11-30T11:38:45.622621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# def predicting2\n",
    "use saved models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9abc28",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-06-28T07:40:50.823354Z",
     "iopub.status.busy": "2023-06-28T07:40:50.822311Z",
     "iopub.status.idle": "2023-06-28T07:40:53.044648Z",
     "shell.execute_reply": "2023-06-28T07:40:53.043655Z"
    },
    "papermill": {
     "duration": 0.137435,
     "end_time": "2023-11-30T11:38:46.029245",
     "exception": false,
     "start_time": "2023-11-30T11:38:45.891810",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "    #model initialized\n",
    "    model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\",num_labels=1)\n",
    "\n",
    "    pthes = [os.path.join(\"./\",s) for s in os.listdir(\"./\") if \".pth\" in s]\n",
    "\n",
    "    def predicting2(\n",
    "        test_dataloader,\n",
    "        model,\n",
    "        pthes \n",
    "    ):\n",
    "\n",
    "        allpreds = []    \n",
    "        for pth in pthes:\n",
    "\n",
    "            state = torch.load(pth)        \n",
    "            model.load_state_dict(state[\"state_dict\"])\n",
    "            model.to(device)\n",
    "            model.eval()      \n",
    "            preds = []\n",
    "            allvalloss=0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for a in test_dataloader:\n",
    "\n",
    "                    ids = a[\"ids\"].to(device)\n",
    "                    mask = a[\"mask\"].to(device)\n",
    "\n",
    "                    output = model(ids,mask)\n",
    "                    output = output[\"logits\"].squeeze(-1)\n",
    "                    preds.append(output.cpu().numpy())\n",
    "\n",
    "                preds = np.concatenate(preds)           \n",
    "                allpreds.append(preds)\n",
    "\n",
    "        return allpreds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc10cc20",
   "metadata": {
    "papermill": {
     "duration": 0.13393,
     "end_time": "2023-11-30T11:38:46.297132",
     "exception": false,
     "start_time": "2023-11-30T11:38:46.163202",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "04eed672",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T11:38:46.573766Z",
     "iopub.status.busy": "2023-11-30T11:38:46.573386Z",
     "iopub.status.idle": "2023-11-30T11:38:50.578287Z",
     "shell.execute_reply": "2023-11-30T11:38:50.576651Z"
    },
    "papermill": {
     "duration": 4.145804,
     "end_time": "2023-11-30T11:38:50.581903",
     "exception": false,
     "start_time": "2023-11-30T11:38:46.436099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "tpreds = predicting(test_dataloader,model)\n",
    "#tpreds = predicting2(test_dataloader,model,pthes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90fa5b4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-30T11:38:50.857453Z",
     "iopub.status.busy": "2023-11-30T11:38:50.856542Z",
     "iopub.status.idle": "2023-11-30T11:38:50.875982Z",
     "shell.execute_reply": "2023-11-30T11:38:50.874753Z"
    },
    "papermill": {
     "duration": 0.160832,
     "end_time": "2023-11-30T11:38:50.878563",
     "exception": false,
     "start_time": "2023-11-30T11:38:50.717731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.0000    0.0000    0.0000        14\n",
      "           2     0.6667    0.2000    0.3077        10\n",
      "           3     0.1818    0.1429    0.1600        14\n",
      "           4     0.1538    0.2400    0.1875        25\n",
      "           5     0.7619    0.8175    0.7887       137\n",
      "\n",
      "    accuracy                         0.6100       200\n",
      "   macro avg     0.3528    0.2801    0.2888       200\n",
      "weighted avg     0.5872    0.6100    0.5903       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_true = p_test['targets']\n",
    "test_pred = []\n",
    "for p in tpreds[0]:\n",
    "    test_pred+=[round(p,0)]\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_true,test_pred,target_names=class_names,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f118427d",
   "metadata": {
    "papermill": {
     "duration": 0.135353,
     "end_time": "2023-11-30T11:38:51.150109",
     "exception": false,
     "start_time": "2023-11-30T11:38:51.014756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 39657,
     "sourceId": 61725,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30513,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3591.536729,
   "end_time": "2023-11-30T11:38:54.648551",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-11-30T10:39:03.111822",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "019a85117ecc42d6904237ab75646fd0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "12536ddaec1d45e1b103046b33d6ea7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1aa6e9a986594c9db34f52fc604492f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5e6b0ad6185e42a895d3355cdb9da3ba",
       "placeholder": "​",
       "style": "IPY_MODEL_4d02b7ec0f38490e9efe924c81580046",
       "value": " 47.4M/47.4M [00:00&lt;00:00, 81.7MB/s]"
      }
     },
     "1e0a19a474cd4fe29e04c01bc7314172": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "24f6d03f982e4cfd929e8cf2dc776f6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c49735f911a54a4f8fa114bb9fe38398",
       "placeholder": "​",
       "style": "IPY_MODEL_a684030a1ed64b1e864f16e3bad37b9d",
       "value": "Downloading model.safetensors: 100%"
      }
     },
     "33b0d12001144c2d9691226e1d0bf9cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9a5d5fc00b2d489685e97c4ef0be9d13",
       "placeholder": "​",
       "style": "IPY_MODEL_6691361066574730834970b0f449bb67",
       "value": " 760k/760k [00:00&lt;00:00, 3.17MB/s]"
      }
     },
     "4a32f089337e46719102cbdd0a630a41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4bc21f72bb73461f9ef4139fafb262b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4d02b7ec0f38490e9efe924c81580046": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "56b3cca476e14d4699413ecafe4435c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e11eeb23bcf04b9c8dfafb937e0f658a",
       "placeholder": "​",
       "style": "IPY_MODEL_b4f317e4b64b419f8b598e6b17420ea4",
       "value": " 684/684 [00:00&lt;00:00, 42.4kB/s]"
      }
     },
     "5e6b0ad6185e42a895d3355cdb9da3ba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "665d177f963c4f338658edec11948074": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6691361066574730834970b0f449bb67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "6f11deb28e8b4cd9aadea3c7eb23eb7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7ced145fe0dc4c07b3145b497328ea9b",
       "max": 760289.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_12536ddaec1d45e1b103046b33d6ea7a",
       "value": 760289.0
      }
     },
     "745eaca7f4f442c29987b9cf753a77bb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ced145fe0dc4c07b3145b497328ea9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8284097e8e2341ce989b233f2a23b5ed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a5d5fc00b2d489685e97c4ef0be9d13": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c6d17b5d0f0444497868c8e8fd35549": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b6544dbf62e44d69973fac164755c8e6",
        "IPY_MODEL_c3fb319c5e3b49cd8cac620cec974640",
        "IPY_MODEL_56b3cca476e14d4699413ecafe4435c1"
       ],
       "layout": "IPY_MODEL_1e0a19a474cd4fe29e04c01bc7314172"
      }
     },
     "a4e0a498b3b547d3b156b0ff9f118bf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d2ab14b13b7747c0814bec365e8993cb",
        "IPY_MODEL_6f11deb28e8b4cd9aadea3c7eb23eb7a",
        "IPY_MODEL_33b0d12001144c2d9691226e1d0bf9cc"
       ],
       "layout": "IPY_MODEL_4a32f089337e46719102cbdd0a630a41"
      }
     },
     "a684030a1ed64b1e864f16e3bad37b9d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "aee271a13da445a58082d83367d5e395": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b4f317e4b64b419f8b598e6b17420ea4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b6544dbf62e44d69973fac164755c8e6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_745eaca7f4f442c29987b9cf753a77bb",
       "placeholder": "​",
       "style": "IPY_MODEL_019a85117ecc42d6904237ab75646fd0",
       "value": "Downloading config.json: 100%"
      }
     },
     "c3fb319c5e3b49cd8cac620cec974640": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cb7fb662276c471c807ebc0316531fa7",
       "max": 684.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4bc21f72bb73461f9ef4139fafb262b2",
       "value": 684.0
      }
     },
     "c49735f911a54a4f8fa114bb9fe38398": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cb7fb662276c471c807ebc0316531fa7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d0080cfb5dbb45a5a4494bb78b2ed0eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8284097e8e2341ce989b233f2a23b5ed",
       "max": 47372894.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_665d177f963c4f338658edec11948074",
       "value": 47372894.0
      }
     },
     "d2ab14b13b7747c0814bec365e8993cb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fb6470e1e6ff4e9f8849005bfce1ce25",
       "placeholder": "​",
       "style": "IPY_MODEL_aee271a13da445a58082d83367d5e395",
       "value": "Downloading spiece.model: 100%"
      }
     },
     "dff270bf366b483d88030a3df392ae46": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_24f6d03f982e4cfd929e8cf2dc776f6f",
        "IPY_MODEL_d0080cfb5dbb45a5a4494bb78b2ed0eb",
        "IPY_MODEL_1aa6e9a986594c9db34f52fc604492f3"
       ],
       "layout": "IPY_MODEL_f5efd59bd7e8464680dc4c74ed0f3f61"
      }
     },
     "e11eeb23bcf04b9c8dfafb937e0f658a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f5efd59bd7e8464680dc4c74ed0f3f61": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "fb6470e1e6ff4e9f8849005bfce1ce25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
